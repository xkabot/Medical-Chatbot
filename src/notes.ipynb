{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Medical Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token limit: number of tokens that can be input. A token is a combination of words similar to a sentence. \n",
    "\n",
    "Chunck overlap: Make the chunks of tokens overlap. \n",
    "\n",
    "## Backend Component\n",
    "Extract data -> create text chuncks -> embedding (vector) -> combine the vectors to create a semantics index -> build knowledge base(!USING PINECONE VECTOR STORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User\n",
    "\n",
    "User asks a question -> query embedding -> knowledge base -> rank result -> llama model -> actual result\n",
    "\n",
    "## Techstack Used\n",
    "Python \n",
    "\n",
    "Langchain (/llamaindex?) -> Gen AI Framework\n",
    "\n",
    "Frontend -> Flask\n",
    "\n",
    "LLM -> Meta Llama 2\n",
    "\n",
    "VectorDB -> Pinecone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
